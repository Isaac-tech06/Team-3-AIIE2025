{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU36A-QY1OBR",
        "outputId": "810504af-93c2-423f-a2f5-91ce41d73efa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /kaggle/input/vehicle-type-recognition\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import shutil\n",
        "import os\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kaggleashwin/vehicle-type-recognition\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctx9lnVY3F7H",
        "outputId": "d24e7bae-c526-41b9-b305-04a2f867e692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset saved at: ./CarMotor_dataset/\n",
            "Dataset saved at: ./CarMotor_dataset/\n"
          ]
        }
      ],
      "source": [
        "local_path = \"./CarMotor_dataset/\"\n",
        "\n",
        "# Ensure the local directory exists\n",
        "os.makedirs(local_path, exist_ok=True)\n",
        "# Copy the dataset to the local directory\n",
        "for item in os.listdir(path):\n",
        "    s = os.path.join(path, item)\n",
        "    d = os.path.join(local_path, item)\n",
        "    if os.path.isdir(s):\n",
        "        shutil.copytree(s, d, dirs_exist_ok=True)\n",
        "    else:\n",
        "        shutil.copy2(s, d)\n",
        "\n",
        "print(f\"Dataset saved at: {local_path}\")\n",
        "\n",
        "print(f\"Dataset saved at: {local_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INlw3JZb3SYF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdnqEl8Q3Yrv",
        "outputId": "32ee58de-991e-47d0-8f71-dbfbf241751b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of image files: 100\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = 'CarMotor_dataset/Dataset/Car'\n",
        "\n",
        "# Count only image files\n",
        "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp')\n",
        "num_images = sum(1 for file in os.listdir(folder_path) if file.lower().endswith(image_extensions))\n",
        "\n",
        "print(f\"Number of image files: {num_images}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVyTrL3K4EzE",
        "outputId": "ad9cbe90-7b1b-4171-ea6d-0159986bd941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of image files: 100\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = 'CarMotor_dataset/Dataset/motorcycle'\n",
        "\n",
        "# Count only image files\n",
        "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp')\n",
        "num_images = sum(1 for file in os.listdir(folder_path) if file.lower().endswith(image_extensions))\n",
        "\n",
        "print(f\"Number of image files: {num_images}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBKgbk4H4jDE",
        "outputId": "d83960d8-57bf-4535-ce1f-6a9924caa8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Images moved into train/ and test/ folders.\n"
          ]
        }
      ],
      "source": [
        "import os, random, shutil\n",
        "\n",
        "# Set up paths\n",
        "source_path = \"CarMotor_dataset/Dataset\"\n",
        "train_path = \"CarMotor_dataset/train\"\n",
        "test_path = \"CarMotor_dataset/test\"\n",
        "classes = [\"Car\", \"motorcycle\"]\n",
        "\n",
        "# Make train and test folders\n",
        "for cls in classes:\n",
        "    os.makedirs(os.path.join(train_path, cls), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_path, cls), exist_ok=True)\n",
        "\n",
        "# Move 80% of images to train, 20% to test\n",
        "for cls in classes:\n",
        "    files = os.listdir(os.path.join(source_path, cls))\n",
        "    random.shuffle(files)\n",
        "\n",
        "    split = int(0.85 * len(files))\n",
        "    train_files = files[:split]\n",
        "    test_files = files[split:]\n",
        "\n",
        "    for f in train_files:\n",
        "        shutil.move(os.path.join(source_path, cls, f), os.path.join(train_path, cls, f))\n",
        "    for f in test_files:\n",
        "        shutil.move(os.path.join(source_path, cls, f), os.path.join(test_path, cls, f))\n",
        "\n",
        "print(\"✅ Images moved into train/ and test/ folders.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV1L9Z8u6WgQ",
        "outputId": "6df4b3d7-8aaa-4313-b1e0-f4a76301d271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 200 images belonging to 2 classes.\n",
            "Found 168 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dir = \"/content/CarMotor_dataset/train\"\n",
        "test_dir = \"/content/CarMotor_dataset/test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hipio6L36oAC",
        "outputId": "8d74a534-a08b-413e-9988-0da98c85b443"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (Car vs Motorcycle)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI7YH-er6wA0",
        "outputId": "37cb1751-e5a5-45a6-b524-9e2ff68d875d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - accuracy: 0.5913 - loss: 0.6693 - val_accuracy: 0.6905 - val_loss: 0.5964\n",
            "Epoch 2/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7202 - loss: 0.5886 - val_accuracy: 0.6845 - val_loss: 0.6828\n",
            "Epoch 3/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.6817 - loss: 0.5525 - val_accuracy: 0.5000 - val_loss: 1.0061\n",
            "Epoch 4/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6647 - loss: 0.6122 - val_accuracy: 0.7143 - val_loss: 0.4842\n",
            "Epoch 5/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7951 - loss: 0.4683 - val_accuracy: 0.8631 - val_loss: 0.3272\n",
            "Epoch 6/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7746 - loss: 0.4316 - val_accuracy: 0.8452 - val_loss: 0.3312\n",
            "Epoch 7/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8362 - loss: 0.3742 - val_accuracy: 0.7798 - val_loss: 0.4347\n",
            "Epoch 8/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - accuracy: 0.8441 - loss: 0.3260 - val_accuracy: 0.8214 - val_loss: 0.4716\n",
            "Epoch 9/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9276 - loss: 0.2439 - val_accuracy: 0.7560 - val_loss: 0.7465\n",
            "Epoch 10/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8423 - loss: 0.4064 - val_accuracy: 0.7976 - val_loss: 0.4804\n",
            "Epoch 11/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8557 - loss: 0.3127 - val_accuracy: 0.8810 - val_loss: 0.2520\n",
            "Epoch 12/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - accuracy: 0.8615 - loss: 0.3465 - val_accuracy: 0.9345 - val_loss: 0.2030\n",
            "Epoch 13/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8346 - loss: 0.3626 - val_accuracy: 0.8512 - val_loss: 0.3012\n",
            "Epoch 14/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8868 - loss: 0.2779 - val_accuracy: 0.8631 - val_loss: 0.3022\n",
            "Epoch 15/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9276 - loss: 0.2238 - val_accuracy: 0.9167 - val_loss: 0.1796\n",
            "Epoch 16/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - accuracy: 0.8942 - loss: 0.2135 - val_accuracy: 0.9226 - val_loss: 0.1699\n",
            "Epoch 17/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9134 - loss: 0.1982 - val_accuracy: 0.8869 - val_loss: 0.3490\n",
            "Epoch 18/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9118 - loss: 0.2384 - val_accuracy: 0.8333 - val_loss: 0.5314\n",
            "Epoch 19/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8736 - loss: 0.2805 - val_accuracy: 0.9643 - val_loss: 0.1100\n",
            "Epoch 20/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8506 - loss: 0.3553 - val_accuracy: 0.9345 - val_loss: 0.1390\n",
            "Epoch 21/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.8349 - loss: 0.3859 - val_accuracy: 0.8690 - val_loss: 0.2589\n",
            "Epoch 22/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8863 - loss: 0.2664 - val_accuracy: 0.9345 - val_loss: 0.1657\n",
            "Epoch 23/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8821 - loss: 0.2716 - val_accuracy: 0.8095 - val_loss: 0.5566\n",
            "Epoch 24/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.8116 - loss: 0.3863 - val_accuracy: 0.9345 - val_loss: 0.1697\n",
            "Epoch 25/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7602 - loss: 0.4510 - val_accuracy: 0.8631 - val_loss: 0.2551\n",
            "Epoch 26/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8339 - loss: 0.3281 - val_accuracy: 0.8988 - val_loss: 0.2269\n",
            "Epoch 27/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8660 - loss: 0.3450 - val_accuracy: 0.9048 - val_loss: 0.1757\n",
            "Epoch 28/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9393 - loss: 0.2333 - val_accuracy: 0.9107 - val_loss: 0.1725\n",
            "Epoch 29/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.9316 - loss: 0.1881 - val_accuracy: 0.9048 - val_loss: 0.2320\n",
            "Epoch 30/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9042 - loss: 0.2231 - val_accuracy: 0.9048 - val_loss: 0.1956\n",
            "Epoch 31/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9582 - loss: 0.1833 - val_accuracy: 0.8988 - val_loss: 0.4173\n",
            "Epoch 32/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8882 - loss: 0.2356 - val_accuracy: 0.9226 - val_loss: 0.1953\n",
            "Epoch 33/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9636 - loss: 0.1674 - val_accuracy: 0.9226 - val_loss: 0.2027\n",
            "Epoch 34/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9421 - loss: 0.2160 - val_accuracy: 0.9345 - val_loss: 0.1699\n",
            "Epoch 35/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - accuracy: 0.9203 - loss: 0.2056 - val_accuracy: 0.9345 - val_loss: 0.1369\n",
            "Epoch 36/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.9561 - loss: 0.1502 - val_accuracy: 0.8988 - val_loss: 0.3446\n",
            "Epoch 37/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9466 - loss: 0.1499 - val_accuracy: 0.8988 - val_loss: 0.2848\n",
            "Epoch 38/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9277 - loss: 0.1419 - val_accuracy: 0.9226 - val_loss: 0.2085\n",
            "Epoch 39/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8857 - loss: 0.1969 - val_accuracy: 0.9583 - val_loss: 0.1192\n",
            "Epoch 40/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9468 - loss: 0.1494 - val_accuracy: 0.9167 - val_loss: 0.2220\n",
            "Epoch 41/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9355 - loss: 0.1886 - val_accuracy: 0.9167 - val_loss: 0.2369\n",
            "Epoch 42/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9483 - loss: 0.1429 - val_accuracy: 0.9524 - val_loss: 0.1032\n",
            "Epoch 43/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.9190 - loss: 0.2171 - val_accuracy: 0.9405 - val_loss: 0.1598\n",
            "Epoch 44/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9245 - loss: 0.1539 - val_accuracy: 0.9167 - val_loss: 0.2260\n",
            "Epoch 45/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9257 - loss: 0.1774 - val_accuracy: 0.9464 - val_loss: 0.1077\n",
            "Epoch 46/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.9432 - loss: 0.1090 - val_accuracy: 0.9405 - val_loss: 0.1564\n",
            "Epoch 47/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.9250 - loss: 0.2365 - val_accuracy: 0.8988 - val_loss: 0.2460\n",
            "Epoch 48/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9511 - loss: 0.1428 - val_accuracy: 0.9286 - val_loss: 0.1827\n",
            "Epoch 49/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.9161 - loss: 0.1536 - val_accuracy: 0.9643 - val_loss: 0.0891\n",
            "Epoch 50/50\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9417 - loss: 0.1356 - val_accuracy: 0.9226 - val_loss: 0.2535\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=test_generator\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqHs1Xdx7GtB"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RChUxw4o7Uqj"
      },
      "outputs": [],
      "source": [
        "print(train_generator.class_indices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ygiaUI78I6f"
      },
      "outputs": [],
      "source": [
        "train_generator.classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yXEjkVc7JpK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def predict_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Normalize\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    label = \"Motorcycle\" if prediction[0][0] > 0.5 else \"Car\"\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Prediction: {label}\", fontsize=14, fontweight='bold')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6Z69QC_7b2h"
      },
      "outputs": [],
      "source": [
        "img_path =\"/content/CarMotor_dataset/test/Car/Image_25.jpg\"\n",
        "print(predict_image(img_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZcAQ2qi7ptx"
      },
      "outputs": [],
      "source": [
        "img_path =\"/content/CarMotor_dataset/test/motorcycle/Image_20.jpg\"\n",
        "print(predict_image(img_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oci961CA7zfj"
      },
      "outputs": [],
      "source": [
        "img_path =\"/content/CarMotor_dataset/test/Car/Image_9.jpg\"\n",
        "print(predict_image(img_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj5Qkl_E-Y3D"
      },
      "outputs": [],
      "source": [
        "img_path=\"/content/CarMotor_dataset/test/motorcycle/Image_45.jpg\"\n",
        "print(predict_image(img_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYak7-4wVyYr"
      },
      "outputs": [],
      "source": [
        "img_path =\"/content/Moto 2.png\"\n",
        "print(predict_image(img_path)) #test with real life photos"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}